{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/napsugark/nyc-taxi-fares-frontend/blob/master/LLM_Learning_Path_1_Intro_NK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introduction to LLMs**\n",
        "\n"
      ],
      "metadata": {
        "id": "sENDVSZ96w3K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Note on running Colab Notebooks:"
      ],
      "metadata": {
        "id": "gEAHGALaWuBV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Colab notebooks, short for Google Colaboratory, are interactive, cloud-based Jupyter notebooks that\n",
        "- allow you to write and execute Python code in your browser\n",
        "- include formatted text using Markdown\n",
        "- provide free access to GPUs and TPUs (which makes them especially useful for machine learning, data science, and AI)\n",
        "- allows you to execute code blocks (cell) independently by using Shift + Enter or clicking the Run button and get instant feedback (outputs, plot).\n",
        "\n",
        "Code cells share the same global state (variables, functions, imports, etc.).\n",
        "Running a cell out of order may result in inconsistent variable states or errors. Jupyter notebooks do not enforce top-to-bottom execution, but following it avoids issues."
      ],
      "metadata": {
        "id": "td-173POTKAv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Note on costs"
      ],
      "metadata": {
        "id": "ScXi1aJVW3YX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use OpenAI models via Azure, you will need access to an Azure Open AI Resource. If you haven't been giving an endpoint and API key, ask your mentors to provide you with one.\n",
        "\n",
        "On that resource there are two deployments, \"gpt-4o-mini\" and \"text-embedding-ada-002\".\n",
        "\n",
        "Please keep in mind that Azure OpenAI is priced as pay-as-you-go on token basis. In other words, any call you make to Azure OpenAI costs and the more text you sent to an LLM and the more text it generates, the costlier it gets. While the per token cost is relatively low (e.g. Chat GPT 40-mini costs 0.63 EUR for 1 million output tokens), for large use cases it can add up easily. Please use the resources carefully, avoid unecessary repetitions of calls and check with your mentors first, if you want to process data that is much larger than any of the examples or assignments. Thank you!   "
      ],
      "metadata": {
        "id": "8BxEqaKUW6Em"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Azure AI Client Setup"
      ],
      "metadata": {
        "id": "Ua92d5Snblls"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Noo6hvw0aL4p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Store AZURE_OPENAI_ENDPOINT and AZURE_OPENAI_API_KEY as secrets (look for the key icon in the sidebar on the left) in your google colab and provide access to them from your notebook (via the toggle next to the variable). These secrets are linked to your google account, somebody else looking at the same notebook won't see them, yet they are available for you in any notebook you open. You will however have to provide notebook access in other notebooks."
      ],
      "metadata": {
        "id": "aZHpOmAUbrlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import AzureOpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "client = AzureOpenAI(\n",
        "    azure_endpoint = userdata.get('AZURE_OPENAI_ENDPOINT'),\n",
        "    api_key=userdata.get('AZURE_OPENAI_API_KEY'),\n",
        "    api_version=\"2024-02-01\" )"
      ],
      "metadata": {
        "id": "ycmCYBqgPDoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Hello there!\"},\n",
        "    ]\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "aQpP9XwdPIMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic concepts to know"
      ],
      "metadata": {
        "id": "nAPmELqs7JkT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "At the end of this module you should have an understanding of the following concepts:\n",
        "- Token\n",
        "- Pretraining\n",
        "- RLHF\n",
        "- Reasoning Models\n",
        "- Embedding\n",
        "- Similarity Metrics\n"
      ],
      "metadata": {
        "id": "EL97m0bx549z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Materials:\n"
      ],
      "metadata": {
        "id": "cGMMYIC_ETNu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should study the following mandatory materials (and any additional materials you find helpful) with the aim of gaining a basic understanding of the concepts listed above."
      ],
      "metadata": {
        "id": "KnXVlCJnEUTa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mandatory\n",
        "\n",
        "- Introduction to LLMs with Andrej Karpathy (1 hour): https://www.youtube.com/watch?v=zjkBMFhNj_g\n",
        "\n",
        "- Embeddings: https://www.datacamp.com/blog/vector-embedding\n",
        "\n",
        "- Similarity Metrics (you can skip the embedding part): https://www.newscatcherapi.com/blog/ultimate-guide-to-text-similarity-with-python#toc-0\n",
        "\n",
        "### Optional\n",
        "\n",
        "Introduction to LLMs:\n",
        "- Microsoft Generative AI for Beginners, Lesson 01 and 02: https://microsoft.github.io/generative-ai-for-beginners/#/\n",
        "\n",
        "\n",
        "Embeddings:\n",
        "- Embedding projector: https://projector.tensorflow.org/\n",
        "- Embeddings technical (section on embeddings only): https://developers.google.com/machine-learning/crash-course/embeddings\n",
        "\n",
        "How do LLMs work?:\n",
        "- Deep Dive into LLMs by Andrej Karpathy (3.5 hrs) : https://www.youtube.com/watch?v=7xTGNNLPyMI\n",
        "- Large Language Models: https://developers.google.com/machine-learning/crash-course/llm\n",
        "- Intro article: https://medium.com/data-science-at-microsoft/how-large-language-models-work-91c362f5b78f\n",
        "\n",
        "\n",
        "NLP:\n",
        "- https://www.deeplearning.ai/resources/natural-language-processing/\n",
        "\n",
        "AI Engineering:\n",
        "- https://newsletter.pragmaticengineer.com/p/ai-engineering-with-chip-huyen?publication_id=458709&amp%3Bpost_id=156423504&amp%3BisFreemail=true&amp%3Br=5i6tv&amp%3BtriedRedirect=true"
      ],
      "metadata": {
        "id": "8RS6LacuEkWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coding"
      ],
      "metadata": {
        "id": "T6e6lEH7HRDA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example: Create a vector ambedding"
      ],
      "metadata": {
        "id": "lMV5q2k7dMSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_sentence = \"This is a sentence about cats\"\n"
      ],
      "metadata": {
        "id": "BJKXFO1ORKsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_embedding = client.embeddings.create(\n",
        "    input=example_sentence,\n",
        "    model=\"text-embedding-ada-002\").data[0].embedding"
      ],
      "metadata": {
        "id": "sBRx92yMZJrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observe that the embedding is a numerical representation of the sentence, with 1536 numbers between -1 and 1 describing the position of the sentence in the embedding space and capturing the semantic meaning of it."
      ],
      "metadata": {
        "id": "0Mk61PY0dZse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_embedding[:20]"
      ],
      "metadata": {
        "id": "L0yZzuT2ZzHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(cat_embedding)"
      ],
      "metadata": {
        "id": "RfBISOIEaKeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example: Calculating the cosine similarity between two embeddings"
      ],
      "metadata": {
        "id": "mUAyIOpDeDff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dog_embedding = client.embeddings.create(\n",
        "    input=\"This is a fun fact about dogs\",\n",
        "    model=\"text-embedding-ada-002\").data[0].embedding"
      ],
      "metadata": {
        "id": "fj2kswW7eLWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def cosine_similarity(u, v):\n",
        "    \"\"\"\n",
        "    Cosine similarity reflects the degree of similariy between u and v\n",
        "\n",
        "    Arguments:\n",
        "        u -- a word vector of shape (n,)\n",
        "        v -- a word vector of shape (n,)\n",
        "\n",
        "    Returns:\n",
        "        cosine_similarity -- the cosine similarity between u and v.\n",
        "    \"\"\"\n",
        "\n",
        "    distance = 0.0\n",
        "\n",
        "    # Compute the dot product between u and v\n",
        "    dot = np.dot(u,v)\n",
        "    # Compute the L2 norm of u\n",
        "    norm_u =  np.linalg.norm(u)\n",
        "\n",
        "    # Compute the L2 norm of v\n",
        "    norm_v =  np.linalg.norm(v)\n",
        "    # Compute the cosine similarity\n",
        "    cosine_similarity = dot/(norm_u*norm_v)\n",
        "\n",
        "\n",
        "    return cosine_similarity\n"
      ],
      "metadata": {
        "id": "fzw2UOHzedOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_similarity(dog_embedding, cat_embedding)"
      ],
      "metadata": {
        "id": "AsPEcoO8ee1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assignment: Cosine similarities"
      ],
      "metadata": {
        "id": "FMCju_Esd5mf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate the cosine similarities of embeddings between the following pairs and compare:\n",
        "- mother and father\n",
        "- car and dog\n",
        "- sun and rain"
      ],
      "metadata": {
        "id": "Fwt39Khru63v"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iwpR9FxbxksU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}